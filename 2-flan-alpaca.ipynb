{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "import pandas as pd\n",
    "from lexical_diversity import lex_div as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'declare-lab/flan-alpaca-large'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_and_scores(prompt, reference):\n",
    "    # Encode & Decode\n",
    "    inputs = tokenizer.encode(prompt + tokenizer.eos_token, return_tensors=\"pt\")\n",
    "    attention_mask = torch.ones(inputs.shape, dtype=torch.long)  # Create attention mask\n",
    "    outputs = model.generate(inputs, attention_mask=attention_mask, max_length=50, num_return_sequences=1, temperature=0.7)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    input_ids = tokenizer.encode(response, return_tensors='pt')\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        \n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(response, reference)\n",
    "\n",
    "    words = response.split()\n",
    "    mtld_score = ld.mtld(words)\n",
    "\n",
    "    response_length = len(response)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Metric': ['ROUGE-1', 'ROUGE-2', 'ROUGE-L'],\n",
    "        'Recall': [scores[0]['rouge-1']['r'], scores[0]['rouge-2']['r'], scores[0]['rouge-l']['r']],\n",
    "        'Precision': [scores[0]['rouge-1']['p'], scores[0]['rouge-2']['p'], scores[0]['rouge-l']['p']],\n",
    "        'F1 Score': [scores[0]['rouge-1']['f'], scores[0]['rouge-2']['f'], scores[0]['rouge-l']['f']],\n",
    "    })\n",
    "\n",
    "    print(f'ROUGE scores\\n{df}')\n",
    "\n",
    "    return response, perplexity.item(), scores, mtld_score, response_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores\n",
      "    Metric    Recall  Precision  F1 Score\n",
      "0  ROUGE-1  0.060606       0.08  0.068966\n",
      "1  ROUGE-2  0.000000       0.00  0.000000\n",
      "2  ROUGE-L  0.060606       0.08  0.068966\n",
      "\n",
      "Response: <pad> The correct technique for the butterfly stroke is to start with the palm facing up and the index finger pointing down. Then, move the index finger to the left and the thumb to the right. Then, move the index finger to the\n",
      "Perplexity: 2.596841812133789\n",
      "MTLD: 20.619584250550332\n",
      "Response length: 227\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"What is the correct technique for the butterfly stroke?\"\n",
    "reference_text = \"Sports, spanning from traditional games like football and tennis to emerging fields like eSports, involve strategic, psychological, nutritional, and physical aspects, and they play a significant role in international unity, technological advancement, scientific understanding, and personal development.\"\n",
    "\n",
    "response, perplexity, rouge_scores, mtld, response_length = get_response_and_scores(new_prompt, reference_text)\n",
    "print('\\nResponse:', response)\n",
    "print('Perplexity:', perplexity)\n",
    "print('MTLD:', mtld)\n",
    "print('Response length:', response_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
